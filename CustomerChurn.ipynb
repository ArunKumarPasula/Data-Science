{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##IMPORTING ALL THE REQUIRED LIBRARIES AND METHODS\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import RandomizedSearchCV,GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Reading data into pandas dataframe\n",
    "df = pd.read_csv(r'C:\\Users\\SVR\\Documents\\Customer Churn\\data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_not_needed = ['State','Account Length','Area Code','Phone']\n",
    "df = df.drop(cols_not_needed,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converting categorical variable into numerical variable\n",
    "def cat_num(label):\n",
    "    if label == \"False.\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "Churn= df['Churn?'].apply(cat_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Churn_int'] = Churn\n",
    "df.drop(['Churn?'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converting categorical variables (Int'l Plan,VMail Plan)into numerical variables\n",
    "mapping_dict = {\n",
    "    \"Int'l Plan\":{\n",
    "        'yes' : 1,\n",
    "        'no' : 0\n",
    "        },\n",
    "    \"VMail Plan\":{\n",
    "        'yes' : 1,\n",
    "        'no' : 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "df = df.replace(mapping_dict)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# selecting features and target variable\n",
    "columns = df.columns.tolist()\n",
    "features = df.columns[:-1].tolist()\n",
    "label = df.columns[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X = df.iloc[:,0:-1]\n",
    "y = df.Churn_int\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#float colummns\n",
    "float_cols = X.select_dtypes(['float']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let us plot histogram of features to understand their distribution\n",
    "fig = plt.figure(figsize = (12,12))\n",
    "\n",
    "for i in range(0,len(float_cols)):\n",
    "    ax = fig.add_subplot(4,2,i+1)\n",
    "    col = float_cols[i]\n",
    "    ax.hist(df[col])\n",
    "    plt.title(col)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#summary of all the features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "pre = preprocessing.StandardScaler()\n",
    "\n",
    "# standardizing features\n",
    "np_scaled = pre.fit_transform(X)\n",
    "df_normalized = pd.DataFrame(np_scaled,columns = features)\n",
    "df_normalized.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_normalized\n",
    "y = df.Churn_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting entire data into train and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X=df_normalized.iloc[:,:-1]\n",
    "y = df.Churn_int\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing all the required classifiers to model the problem at hand\n",
    "from sklearn.cross_validation import cross_val_score,KFold,cross_val_predict\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "###kf = KFold(X.shape[0],random_state = 1)\n",
    "logreg = LR()\n",
    "knn     = KNN()\n",
    "rf  = RF()\n",
    "support_vector_machine  = svm.SVC()\n",
    "\n",
    "classifiers = ['Logistic_Regression','KnearestNeighbors','RandomForest','Support Vector Machine']\n",
    "estimators_ojects = [logreg,knn,rf,support_vector_machine]\n",
    "'''scores = cross_val_score(logreg,X,y,cv=3)\n",
    "scores = pd.Series(scores)\n",
    "scores.mean()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to calculate accuracies of each model which is fitted to the data\n",
    "def accuracy_using_cv(estimators_objects):\n",
    "    accuracies = []\n",
    "    for est in estimators_objects:\n",
    "        kf = KFold(X.shape[0], random_state=1)\n",
    "        scores = cross_val_score(est,X,y,cv = kf)\n",
    "        scores = pd.Series(scores).mean()\n",
    "        #scores = scores.mean()\n",
    "        accuracies.append(scores)\n",
    "        print('The Avg Accuracy of classifier %s using 3 fold CV is %f' %(est,scores),'\\n \\n')\n",
    "    return accuracies\n",
    "\n",
    "accuracy = accuracy_using_cv(estimators_ojects)\n",
    "accuracy\n",
    "index = accuracy.index(max(accuracy))\n",
    "print('Classifier %s has highest accuarcy with %f' %(classifiers[index],max(accuracy)) )\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# null accuracy ,.ie., predicting all the labels as the one which has majority\n",
    "y_test.value_counts().head(1)/len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to find confusion matrices,Precision,Recall and F1 scores of the classifiers\n",
    "from collections import defaultdict\n",
    "confusion_matrices = defaultdict(dict)\n",
    "recall_scores = {}\n",
    "accuracy_scores = {}\n",
    "f1_scores = {}\n",
    "auc = {}\n",
    "for est in estimators_ojects:\n",
    "    est.fit(X_train,y_train)\n",
    "    y_pred_class = est.predict(X_test)\n",
    "    matrix = metrics.confusion_matrix(y_test,y_pred_class)\n",
    "    recall_score = metrics.recall_score(y_test,y_pred_class)\n",
    "    accuracy = metrics.accuracy_score(y_test,y_pred_class)\n",
    "    f1_score = metrics.f1_score(y_test,y_pred_class)\n",
    "    aucs = metrics.roc_auc_score(y_test,y_pred_class)\n",
    "    confusion_matrices[classifiers[estimators_ojects.index(est)]] = matrix\n",
    "    recall_scores[classifiers[estimators_ojects.index(est)]] = recall_score\n",
    "    accuracy_scores[classifiers[estimators_ojects.index(est)]] = accuracy\n",
    "    f1_scores[classifiers[estimators_ojects.index(est)]] = f1_score\n",
    "    auc[classifiers[estimators_ojects.index(est)]] = aucs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# installing seaborn library for plotting\n",
    "!conda install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing seaborn library and plotting confusion matrices which tells us about true positives,true negatives,false positives,false negatives\n",
    "import seaborn as sns\n",
    "fix, ax = plt.subplots(figsize=(16, 12))\n",
    "plt.suptitle('Confusion Matrix of Various Classifiers')\n",
    "i =1 \n",
    "for k,val in confusion_matrices.items():\n",
    "    plt.subplot(2,2,i)\n",
    "    plt.title(k)\n",
    "    sns.heatmap(val,annot=True,  fmt='')\n",
    "    i = i+1\n",
    "    #sns.plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##classifier with max recall score\n",
    "max(recall_scores, key = lambda x: recall_scores.get(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##classifier with max accuracy score\n",
    "max(accuracy_scores,key = lambda x : accuracy_scores.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a good classifier F1 score (HM of precison and recall) is 1.We can take out Logistic Regression classifier as it has only 0.23 F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a good classifier AUC should have max value,here RF performs well.For all the above metrics,RF is consistently performing well.So,will choose RF as our final model and let us try to build a best RF classfier by tuning the parameters of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implementation of RF\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "rf = RF()\n",
    "rf_fit = rf.fit(X_train, y_train)\n",
    "y_pred_test = rf_fit.predict(X_test)\n",
    "\n",
    "print ('CONFUSION MATRIX :\\n\\n',metrics.confusion_matrix(y_test,y_pred_test),'\\n\\n')\n",
    "print ('ACCURACY SCORE :',metrics.accuracy_score(y_test,y_pred_test),'\\n\\n')\n",
    "print ('CLASSIFICATION REPORT:\\n\\n',metrics.classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_grid = { \n",
    "    'n_estimators': [i for i in range(200,1,-10)],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "#scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us tune the hyperparameters of Random Forest classifier using GridSearch technique, which takes the set of all possible parameters combination given to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "rf = RF()\n",
    "#kf = KFold(len(X), n_folds=10,shuffle=True, random_state=1)\n",
    "rf_gs = GridSearchCV(estimator=rf,param_grid = parameter_grid,cv = 10,scoring = 'accuracy',n_jobs=-1)\n",
    "rf_gs.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_gs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_scores = [result.mean_validation_score for result in rf_gs.grid_scores_]\n",
    "mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(rf_gs.best_score_)\n",
    "print(rf_gs.best_params_)\n",
    "print(rf_gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# printing accuracy score,roc_auc_score,classification report for the classifier with the best set of parameters selected by the grid search\n",
    "pred = rf_gs.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,pred))\n",
    "print()\n",
    "print(metrics.accuracy_score(y_test,pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_test,pred))\n",
    "print()\n",
    "print(metrics.roc_auc_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "rf = RandomForestClassifier(n_estimators = 160,max_features = 'log2',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let us perfor random search for the best set of paramters\n",
    "paramet_grid = { \n",
    "    'n_estimators': [i for i in range(300,1,-10)],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "#scores = ['precision', 'recall']\n",
    "rf_rs = RandomizedSearchCV(rf,paramet_grid,cv = 10,scoring = 'accuracy',n_jobs = -1,n_iter = 10,random_state = 4)\n",
    "rf_rs.fit(X,y)\n",
    "rf_rs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(rf_rs.best_score_)\n",
    "print(rf_rs.best_params_)\n",
    "print(rf_rs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!conda install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''export_graphviz(rf,\n",
    "                feature_names=X.columns,\n",
    "                filled=True,\n",
    "                rounded=True)'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.system('dot -Tpng tree.dot -o tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(\"Features sorted by their score:\")\n",
    "#print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
